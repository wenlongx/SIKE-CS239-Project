[2019-12-07 00:08:50,095] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [http://0.0.0.0:8081]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 00:08:50,130] INFO Logging initialized @432ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 00:09:20,863] ERROR Server died unexpectedly:  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server 'localhost:2181' with timeout of 30000 ms
	at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:1233)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:157)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:131)
	at kafka.utils.ZkUtils$.createZkClientAndConnection(ZkUtils.scala:93)
	at kafka.utils.ZkUtils$.apply(ZkUtils.scala:75)
	at kafka.utils.ZkUtils.apply(ZkUtils.scala)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig.zkUtils(SchemaRegistryConfig.java:695)
	at io.confluent.kafka.schemaregistry.id.ZookeeperIdGenerator.configure(ZookeeperIdGenerator.java:65)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.identityGenerator(KafkaSchemaRegistry.java:182)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:138)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:62)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:81)
	at io.confluent.rest.Application.createServer(Application.java:205)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:42)
[2019-12-07 00:54:51,430] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [http://0.0.0.0:8081]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 00:54:51,476] INFO Logging initialized @401ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 00:54:52,514] INFO Created schema registry namespace localhost:2181 /schema_registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 00:54:52,636] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://kaushik-HP:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 00:54:52,816] INFO Creating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 00:54:52,818] WARN Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 00:54:53,161] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 00:54:53,239] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 00:54:53,242] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 00:54:53,440] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryInitializationException: Error initializing kafka store while initializing schema registry
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:224)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:66)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:81)
	at io.confluent.rest.Application.createServer(Application.java:205)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:42)
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreInitializationException: io.confluent.kafka.schemaregistry.storage.exceptions.StoreException: Failed to write Noop record to kafka store.
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:142)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:222)
	... 4 more
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreException: Failed to write Noop record to kafka store.
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getLatestOffset(KafkaStore.java:439)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.waitUntilKafkaReaderReachesLastOffset(KafkaStore.java:281)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:140)
	... 5 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:98)
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:81)
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:30)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getLatestOffset(KafkaStore.java:434)
	... 7 more
Caused by: org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
[2019-12-07 00:57:07,383] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [http://0.0.0.0:8081]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 00:57:07,417] INFO Logging initialized @378ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 00:57:08,007] INFO Created schema registry namespace localhost:2181 /schema_registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 00:57:08,114] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://kaushik-HP:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 00:57:08,320] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 00:57:08,328] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 00:57:08,381] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 00:57:08,428] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 00:57:08,429] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 00:57:08,510] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryInitializationException: Error initializing kafka store while initializing schema registry
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:224)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:66)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:81)
	at io.confluent.rest.Application.createServer(Application.java:205)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:42)
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreInitializationException: io.confluent.kafka.schemaregistry.storage.exceptions.StoreException: Failed to write Noop record to kafka store.
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:142)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:222)
	... 4 more
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreException: Failed to write Noop record to kafka store.
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getLatestOffset(KafkaStore.java:439)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.waitUntilKafkaReaderReachesLastOffset(KafkaStore.java:281)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:140)
	... 5 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:98)
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:81)
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:30)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getLatestOffset(KafkaStore.java:434)
	... 7 more
Caused by: org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
[2019-12-07 01:02:48,510] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [http://0.0.0.0:8081]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 01:02:48,544] INFO Logging initialized @396ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 01:02:49,164] INFO Created schema registry namespace localhost:2181 /schema_registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 01:02:49,295] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://kaushik-HP:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:02:49,493] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:02:49,502] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:02:49,542] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:02:49,583] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:02:49,584] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:02:49,663] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryInitializationException: Error initializing kafka store while initializing schema registry
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:224)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:66)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:81)
	at io.confluent.rest.Application.createServer(Application.java:205)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:42)
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreInitializationException: io.confluent.kafka.schemaregistry.storage.exceptions.StoreException: Failed to write Noop record to kafka store.
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:142)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:222)
	... 4 more
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreException: Failed to write Noop record to kafka store.
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getLatestOffset(KafkaStore.java:439)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.waitUntilKafkaReaderReachesLastOffset(KafkaStore.java:281)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:140)
	... 5 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:98)
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:81)
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:30)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getLatestOffset(KafkaStore.java:434)
	... 7 more
Caused by: org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
[2019-12-07 01:03:43,526] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [http://0.0.0.0:9092]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 01:03:43,560] INFO Logging initialized @400ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 01:03:44,128] INFO Created schema registry namespace localhost:2181 /schema_registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 01:03:44,232] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://kaushik-HP:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:03:44,418] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:03:44,426] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:03:44,464] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:03:44,508] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:03:44,509] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:03:44,587] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryInitializationException: Error initializing kafka store while initializing schema registry
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:224)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:66)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:81)
	at io.confluent.rest.Application.createServer(Application.java:205)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:42)
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreInitializationException: io.confluent.kafka.schemaregistry.storage.exceptions.StoreException: Failed to write Noop record to kafka store.
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:142)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:222)
	... 4 more
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreException: Failed to write Noop record to kafka store.
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getLatestOffset(KafkaStore.java:439)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.waitUntilKafkaReaderReachesLastOffset(KafkaStore.java:281)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:140)
	... 5 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:98)
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:81)
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:30)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getLatestOffset(KafkaStore.java:434)
	... 7 more
Caused by: org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
[2019-12-07 01:03:58,306] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [localhost:9092]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 01:03:58,339] INFO Logging initialized @395ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 01:03:58,503] ERROR Server died unexpectedly:  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
org.apache.kafka.common.config.ConfigException: Found a listener without a port. All listeners must have a port. The listener without a port is: localhost:9092
	at io.confluent.rest.Application.parseListeners(Application.java:627)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.getSchemeAndPortForIdentity(KafkaSchemaRegistry.java:201)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:121)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:62)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:81)
	at io.confluent.rest.Application.createServer(Application.java:205)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:42)
[2019-12-07 01:04:07,107] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [http://0.0.0.0:8081]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 01:04:07,142] INFO Logging initialized @390ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 01:04:07,716] INFO Created schema registry namespace localhost:2181 /schema_registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 01:04:07,822] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://kaushik-HP:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:04:08,010] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:04:08,020] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:04:08,060] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:04:08,102] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:04:08,103] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:04:08,333] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryInitializationException: Error initializing kafka store while initializing schema registry
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:224)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:66)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:81)
	at io.confluent.rest.Application.createServer(Application.java:205)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:42)
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreInitializationException: io.confluent.kafka.schemaregistry.storage.exceptions.StoreException: Failed to write Noop record to kafka store.
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:142)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:222)
	... 4 more
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreException: Failed to write Noop record to kafka store.
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getLatestOffset(KafkaStore.java:439)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.waitUntilKafkaReaderReachesLastOffset(KafkaStore.java:281)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:140)
	... 5 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:98)
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:81)
	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:30)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getLatestOffset(KafkaStore.java:434)
	... 7 more
Caused by: org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
[2019-12-07 01:10:52,517] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [http://0.0.0.0:8081]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 01:10:52,550] INFO Logging initialized @393ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 01:10:53,143] INFO Created schema registry namespace localhost:2181 /schema_registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 01:10:53,251] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://kaushik-HP:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:10:53,441] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:10:53,450] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:10:53,502] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:10:53,546] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:10:53,547] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 01:10:53,665] INFO Wait to catch up until the offset of the last message at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:10:53,700] INFO Joining schema registry with Zookeeper-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2019-12-07 01:10:53,716] INFO Successfully elected the new master: {"host":"kaushik-HP","port":8081,"master_eligibility":true,"scheme":"http","version":1} (io.confluent.kafka.schemaregistry.masterelector.zookeeper.ZookeeperMasterElector)
[2019-12-07 01:10:53,729] INFO Wait to catch up until the offset of the last message at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 01:10:53,731] INFO Successfully elected the new master: {"host":"kaushik-HP","port":8081,"master_eligibility":true,"scheme":"http","version":1} (io.confluent.kafka.schemaregistry.masterelector.zookeeper.ZookeeperMasterElector)
[2019-12-07 01:10:53,830] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.Application)
[2019-12-07 01:10:54,237] INFO jetty-9.4.18.v20190429; built: 2019-04-29T20:42:08.989Z; git: e1bc35120a6617ee3df052294e433f3a25ce7097; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10 (org.eclipse.jetty.server.Server)
[2019-12-07 01:10:54,359] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2019-12-07 01:10:54,360] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2019-12-07 01:10:54,365] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2019-12-07 01:10:54,987] INFO HV000001: Hibernate Validator 5.1.3.Final (org.hibernate.validator.internal.util.Version)
[2019-12-07 01:10:55,134] INFO Started o.e.j.s.ServletContextHandler@40dff0b7{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 01:10:55,147] INFO Started o.e.j.s.ServletContextHandler@53142455{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 01:10:55,168] INFO Started NetworkTrafficServerConnector@366ac49b{HTTP/1.1,[http/1.1]}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2019-12-07 01:10:55,169] INFO Started @3014ms (org.eclipse.jetty.server.Server)
[2019-12-07 01:10:55,169] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2019-12-07 02:46:54,668] INFO Wait to catch up until the offset of the last message at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 02:46:54,769] INFO 127.0.0.1 - - [07/Dec/2019:10:46:54 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  408 (io.confluent.rest-utils.requests)
[2019-12-07 02:48:33,569] INFO 127.0.0.1 - - [07/Dec/2019:10:48:33 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  14 (io.confluent.rest-utils.requests)
[2019-12-07 02:48:33,583] INFO 127.0.0.1 - - [07/Dec/2019:10:48:33 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 365  13 (io.confluent.rest-utils.requests)
[2019-12-07 02:56:47,013] INFO Stopped NetworkTrafficServerConnector@366ac49b{HTTP/1.1,[http/1.1]}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2019-12-07 02:56:47,014] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2019-12-07 02:56:47,015] INFO Stopped o.e.j.s.ServletContextHandler@53142455{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 02:56:47,023] INFO Stopped o.e.j.s.ServletContextHandler@40dff0b7{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 02:56:47,027] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2019-12-07 02:56:47,029] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 02:56:47,030] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 02:56:47,031] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 02:56:47,033] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:10:55,969] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [http://0.0.0.0:8081]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 06:10:56,124] INFO Logging initialized @2046ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 06:10:57,418] INFO Created schema registry namespace localhost:2181 /schema_registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 06:10:57,617] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://kaushik-HP:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:10:57,903] INFO Creating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:10:57,905] WARN Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:10:58,194] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:10:58,249] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:10:58,249] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:10:58,383] INFO Wait to catch up until the offset of the last message at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:10:58,499] INFO Joining schema registry with Zookeeper-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2019-12-07 06:10:58,551] INFO Successfully elected the new master: {"host":"kaushik-HP","port":8081,"master_eligibility":true,"scheme":"http","version":1} (io.confluent.kafka.schemaregistry.masterelector.zookeeper.ZookeeperMasterElector)
[2019-12-07 06:10:58,588] INFO Successfully elected the new master: {"host":"kaushik-HP","port":8081,"master_eligibility":true,"scheme":"http","version":1} (io.confluent.kafka.schemaregistry.masterelector.zookeeper.ZookeeperMasterElector)
[2019-12-07 06:10:58,616] INFO Wait to catch up until the offset of the last message at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:10:59,061] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.Application)
[2019-12-07 06:10:59,782] INFO jetty-9.4.18.v20190429; built: 2019-04-29T20:42:08.989Z; git: e1bc35120a6617ee3df052294e433f3a25ce7097; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10 (org.eclipse.jetty.server.Server)
[2019-12-07 06:10:59,844] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2019-12-07 06:10:59,844] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2019-12-07 06:10:59,846] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2019-12-07 06:11:00,730] INFO HV000001: Hibernate Validator 5.1.3.Final (org.hibernate.validator.internal.util.Version)
[2019-12-07 06:11:00,895] INFO Started o.e.j.s.ServletContextHandler@708400f6{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 06:11:00,906] INFO Started o.e.j.s.ServletContextHandler@4cf8b2dc{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 06:11:00,949] INFO Started NetworkTrafficServerConnector@305a0c5f{HTTP/1.1,[http/1.1]}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2019-12-07 06:11:00,950] INFO Started @6874ms (org.eclipse.jetty.server.Server)
[2019-12-07 06:11:00,950] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2019-12-07 06:12:03,675] INFO Wait to catch up until the offset of the last message at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:12:03,777] INFO 127.0.0.1 - - [07/Dec/2019:14:12:02 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  1419 (io.confluent.rest-utils.requests)
[2019-12-07 06:13:26,906] INFO 127.0.0.1 - - [07/Dec/2019:14:13:26 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  17 (io.confluent.rest-utils.requests)
[2019-12-07 06:13:26,974] INFO 127.0.0.1 - - [07/Dec/2019:14:13:26 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 365  8 (io.confluent.rest-utils.requests)
[2019-12-07 06:13:27,093] INFO Wait to catch up until the offset of the last message at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:13:27,151] INFO 127.0.0.1 - - [07/Dec/2019:14:13:27 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  65 (io.confluent.rest-utils.requests)
[2019-12-07 06:13:27,169] INFO 127.0.0.1 - - [07/Dec/2019:14:13:27 +0000] "GET /schemas/ids/2 HTTP/1.1" 200 339  3 (io.confluent.rest-utils.requests)
[2019-12-07 06:13:27,231] INFO Wait to catch up until the offset of the last message at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:13:27,251] INFO 127.0.0.1 - - [07/Dec/2019:14:13:27 +0000] "POST /subjects/test-value/versions HTTP/1.1" 409 93  23 (io.confluent.rest-utils.requests)
[2019-12-07 06:25:33,513] INFO 127.0.0.1 - - [07/Dec/2019:14:25:33 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  4 (io.confluent.rest-utils.requests)
[2019-12-07 06:25:33,593] INFO 127.0.0.1 - - [07/Dec/2019:14:25:33 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 365  3 (io.confluent.rest-utils.requests)
[2019-12-07 06:25:33,679] INFO 127.0.0.1 - - [07/Dec/2019:14:25:33 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  4 (io.confluent.rest-utils.requests)
[2019-12-07 06:25:33,729] INFO 127.0.0.1 - - [07/Dec/2019:14:25:33 +0000] "GET /schemas/ids/2 HTTP/1.1" 200 339  2 (io.confluent.rest-utils.requests)
[2019-12-07 06:25:33,781] INFO Wait to catch up until the offset of the last message at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:25:33,786] INFO 127.0.0.1 - - [07/Dec/2019:14:25:33 +0000] "POST /subjects/test-value/versions HTTP/1.1" 409 93  10 (io.confluent.rest-utils.requests)
[2019-12-07 06:26:12,412] INFO Stopped NetworkTrafficServerConnector@305a0c5f{HTTP/1.1,[http/1.1]}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2019-12-07 06:26:12,413] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2019-12-07 06:26:12,419] INFO Stopped o.e.j.s.ServletContextHandler@4cf8b2dc{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 06:26:12,441] INFO Stopped o.e.j.s.ServletContextHandler@708400f6{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 06:26:12,444] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2019-12-07 06:26:12,445] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:26:12,446] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:26:12,446] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:26:12,448] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:26:16,352] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [http://0.0.0.0:8081]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 06:26:16,387] INFO Logging initialized @384ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 06:26:16,996] INFO Created schema registry namespace localhost:2181 /schema_registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 06:26:17,120] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://kaushik-HP:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:26:17,319] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:26:17,328] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:26:17,373] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:26:17,415] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:26:17,416] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:26:17,516] INFO Wait to catch up until the offset of the last message at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:26:17,564] INFO Joining schema registry with Zookeeper-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2019-12-07 06:26:17,585] INFO Successfully elected the new master: {"host":"kaushik-HP","port":8081,"master_eligibility":true,"scheme":"http","version":1} (io.confluent.kafka.schemaregistry.masterelector.zookeeper.ZookeeperMasterElector)
[2019-12-07 06:26:17,600] INFO Wait to catch up until the offset of the last message at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:26:17,604] INFO Successfully elected the new master: {"host":"kaushik-HP","port":8081,"master_eligibility":true,"scheme":"http","version":1} (io.confluent.kafka.schemaregistry.masterelector.zookeeper.ZookeeperMasterElector)
[2019-12-07 06:26:17,689] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.Application)
[2019-12-07 06:26:17,982] INFO jetty-9.4.18.v20190429; built: 2019-04-29T20:42:08.989Z; git: e1bc35120a6617ee3df052294e433f3a25ce7097; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10 (org.eclipse.jetty.server.Server)
[2019-12-07 06:26:18,021] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2019-12-07 06:26:18,021] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2019-12-07 06:26:18,025] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2019-12-07 06:26:18,810] INFO HV000001: Hibernate Validator 5.1.3.Final (org.hibernate.validator.internal.util.Version)
[2019-12-07 06:26:18,968] INFO Started o.e.j.s.ServletContextHandler@753432a2{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 06:26:18,984] INFO Started o.e.j.s.ServletContextHandler@34f7234e{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 06:26:18,994] INFO Started NetworkTrafficServerConnector@68be8808{HTTP/1.1,[http/1.1]}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2019-12-07 06:26:18,995] INFO Started @2995ms (org.eclipse.jetty.server.Server)
[2019-12-07 06:26:18,995] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2019-12-07 06:26:35,593] INFO 127.0.0.1 - - [07/Dec/2019:14:26:35 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  254 (io.confluent.rest-utils.requests)
[2019-12-07 06:26:35,672] INFO 127.0.0.1 - - [07/Dec/2019:14:26:35 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 365  12 (io.confluent.rest-utils.requests)
[2019-12-07 06:26:35,759] INFO 127.0.0.1 - - [07/Dec/2019:14:26:35 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  6 (io.confluent.rest-utils.requests)
[2019-12-07 06:26:35,801] INFO 127.0.0.1 - - [07/Dec/2019:14:26:35 +0000] "GET /schemas/ids/2 HTTP/1.1" 200 339  3 (io.confluent.rest-utils.requests)
[2019-12-07 06:26:35,850] INFO Wait to catch up until the offset of the last message at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:26:35,884] INFO 127.0.0.1 - - [07/Dec/2019:14:26:35 +0000] "POST /subjects/test-value/versions HTTP/1.1" 409 93  38 (io.confluent.rest-utils.requests)
[2019-12-07 06:35:33,236] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2019:14:35:33 +0000] "GET / HTTP/1.1" 200 2  13 (io.confluent.rest-utils.requests)
[2019-12-07 06:35:33,437] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2019:14:35:33 +0000] "GET /favicon.ico HTTP/1.1" 404 49  2 (io.confluent.rest-utils.requests)
[2019-12-07 06:35:55,852] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2019:14:35:55 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2019-12-07 06:40:38,642] INFO 127.0.0.1 - - [07/Dec/2019:14:40:38 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  8 (io.confluent.rest-utils.requests)
[2019-12-07 06:40:38,732] INFO 127.0.0.1 - - [07/Dec/2019:14:40:38 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 365  3 (io.confluent.rest-utils.requests)
[2019-12-07 06:42:39,931] INFO 127.0.0.1 - - [07/Dec/2019:14:42:39 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  5 (io.confluent.rest-utils.requests)
[2019-12-07 06:42:40,014] INFO 127.0.0.1 - - [07/Dec/2019:14:42:40 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 365  3 (io.confluent.rest-utils.requests)
[2019-12-07 06:42:40,114] INFO 127.0.0.1 - - [07/Dec/2019:14:42:40 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  4 (io.confluent.rest-utils.requests)
[2019-12-07 06:42:40,279] INFO 127.0.0.1 - - [07/Dec/2019:14:42:40 +0000] "GET /schemas/ids/2 HTTP/1.1" 200 339  11 (io.confluent.rest-utils.requests)
[2019-12-07 06:43:52,079] INFO 127.0.0.1 - - [07/Dec/2019:14:43:52 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  4 (io.confluent.rest-utils.requests)
[2019-12-07 06:43:52,177] INFO 127.0.0.1 - - [07/Dec/2019:14:43:52 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 365  3 (io.confluent.rest-utils.requests)
[2019-12-07 06:44:21,635] INFO Stopped NetworkTrafficServerConnector@68be8808{HTTP/1.1,[http/1.1]}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2019-12-07 06:44:21,636] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2019-12-07 06:44:21,643] INFO Stopped o.e.j.s.ServletContextHandler@34f7234e{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 06:44:21,656] INFO Stopped o.e.j.s.ServletContextHandler@753432a2{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 06:44:21,658] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2019-12-07 06:44:21,659] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:44:21,660] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:44:21,660] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:44:21,663] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:44:24,478] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = backward
	compression.enable = true
	debug = false
	host.name = kaushik-HP
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = []
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.zk.session.timeout.ms = 30000
	listeners = [http://0.0.0.0:8081]
	master.eligibility = true
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = false
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 06:44:24,512] INFO Logging initialized @379ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2019-12-07 06:44:25,133] INFO Created schema registry namespace localhost:2181 /schema_registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2019-12-07 06:44:25,280] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://kaushik-HP:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:44:25,471] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:44:25,480] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:44:25,527] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:44:25,569] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:44:25,570] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2019-12-07 06:44:25,645] INFO Wait to catch up until the offset of the last message at 6 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:44:25,692] INFO Joining schema registry with Zookeeper-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2019-12-07 06:44:25,712] INFO Successfully elected the new master: {"host":"kaushik-HP","port":8081,"master_eligibility":true,"scheme":"http","version":1} (io.confluent.kafka.schemaregistry.masterelector.zookeeper.ZookeeperMasterElector)
[2019-12-07 06:44:25,724] INFO Wait to catch up until the offset of the last message at 7 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:44:25,737] INFO Successfully elected the new master: {"host":"kaushik-HP","port":8081,"master_eligibility":true,"scheme":"http","version":1} (io.confluent.kafka.schemaregistry.masterelector.zookeeper.ZookeeperMasterElector)
[2019-12-07 06:44:25,830] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.Application)
[2019-12-07 06:44:26,014] INFO jetty-9.4.18.v20190429; built: 2019-04-29T20:42:08.989Z; git: e1bc35120a6617ee3df052294e433f3a25ce7097; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10 (org.eclipse.jetty.server.Server)
[2019-12-07 06:44:26,046] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2019-12-07 06:44:26,046] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2019-12-07 06:44:26,048] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2019-12-07 06:44:26,702] INFO HV000001: Hibernate Validator 5.1.3.Final (org.hibernate.validator.internal.util.Version)
[2019-12-07 06:44:26,863] INFO Started o.e.j.s.ServletContextHandler@753432a2{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 06:44:26,897] INFO Started o.e.j.s.ServletContextHandler@34f7234e{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2019-12-07 06:44:26,918] INFO Started NetworkTrafficServerConnector@68be8808{HTTP/1.1,[http/1.1]}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2019-12-07 06:44:26,919] INFO Started @2788ms (org.eclipse.jetty.server.Server)
[2019-12-07 06:44:26,920] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2019-12-07 06:44:41,478] INFO 127.0.0.1 - - [07/Dec/2019:14:44:41 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  291 (io.confluent.rest-utils.requests)
[2019-12-07 06:44:41,547] INFO 127.0.0.1 - - [07/Dec/2019:14:44:41 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 365  7 (io.confluent.rest-utils.requests)
[2019-12-07 06:44:41,623] INFO 127.0.0.1 - - [07/Dec/2019:14:44:41 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  6 (io.confluent.rest-utils.requests)
[2019-12-07 06:44:41,792] INFO 127.0.0.1 - - [07/Dec/2019:14:44:41 +0000] "GET /schemas/ids/2 HTTP/1.1" 200 339  11 (io.confluent.rest-utils.requests)
[2019-12-07 06:44:41,902] INFO Wait to catch up until the offset of the last message at 7 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2019-12-07 06:44:41,929] INFO 127.0.0.1 - - [07/Dec/2019:14:44:41 +0000] "POST /subjects/test-value/versions HTTP/1.1" 409 93  32 (io.confluent.rest-utils.requests)
[2019-12-07 06:47:14,542] INFO 127.0.0.1 - - [07/Dec/2019:14:47:14 +0000] "POST /subjects/test-value/versions HTTP/1.1" 200 8  5 (io.confluent.rest-utils.requests)
